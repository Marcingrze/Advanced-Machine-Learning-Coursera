{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "colab_type": "code",
        "id": "op1vO6SbGIbK",
        "outputId": "a03046a6-0a5b-4458-82b9-3923e2c2d814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-08-08 07:47:21--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-08 07:47:21 (44.7 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "\n",
        "setup_google_colab.setup_week5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AkZenhrOF0C7"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "ig6UPODhF0DD",
        "outputId": "e2d88822-d378-4e9b-b297-7c3d6e58780a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.8.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using Theano backend.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "irg4aY_MF0DQ"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "kV_td4mDF0DT"
      },
      "outputs": [],
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "colab_type": "code",
        "id": "uoO-uXVqF0Da",
        "outputId": "952878b5-857c-4d56-bed8-7a719f9902f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ]
        }
      ],
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "colab_type": "code",
        "id": "KC48QNXLF0Dk",
        "outputId": "98bce73f-dff1-4246-bd37-393c72ce9c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sBLWSNRkF0Do"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "f_JX1TLTF0Dq",
        "outputId": "636cbcdb-8bfd-4fc9-9322-117f629bb625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ]
        }
      ],
      "source": [
        "tokens = list(set(''.join(names))) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5XsdjevnF0Dz"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "seEXIds3F0D1"
      },
      "outputs": [],
      "source": [
        "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "for index, token in enumerate(tokens):\n",
        "    token_to_id[token] = index\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "KylWmvLwF0D7"
      },
      "outputs": [],
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "colab_type": "code",
        "id": "B4Fo44FXF0EG",
        "outputId": "58e090f3-f699-4b43-d609-7bfdb58760ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[54  4  9 45 46 45 33 37  0]\n",
            " [54 20 37  6  1 18  0  0  0]\n",
            " [54 40  1 44 34 34 44 33  0]\n",
            " [54 20 44  6 32 45 49 49 33]]\n"
          ]
        }
      ],
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ItFYyQrF0EK"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "colab_type": "code",
        "id": "BTxvvWX4F0EM",
        "outputId": "253c4706-cdd2-41ef-842c-77c5d1b79c1c"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'keras.backend' has no attribute 'clear_session'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-df6e6d1d0271>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# remember to reset your session if you change your graph!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_tf_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32me:\\GitHub\\Advanced-Machine-Learning-Coursera\\Course_1-Introduction_to_Deep_Learning\\Week-5\\keras_utils.py\u001b[0m in \u001b[0;36mreset_tf_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mcurr_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m# reset graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;31m# create new session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'clear_session'"
          ]
        }
      ],
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "PmNQQTZ4F0EV"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation = 'relu') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = 'softmax') ### YOUR CODE HERE "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ChfnRPzQF0EY"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "l3PzBBX0F0Ea"
      },
      "outputs": [],
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YSZXQDbLF0Eg"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "Ze0gEqzKF0Eh"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Layer embedding_1 was called with an input that isn't a symbolic tensor. Received type: <class 'tensorflow.python.framework.ops.Tensor'>. Full input: [<tf.Tensor 'Reshape:0' shape=(?, 1) dtype=int32>]. All inputs to the layer should be tensors.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    215\u001b[0m                           T.sharedvar.TensorSharedVariable)):\n\u001b[1;32m--> 216\u001b[1;33m         raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n\u001b[0m\u001b[0;32m    217\u001b[0m                          'Expected a symbolic tensor instance.')\n",
            "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'tensorflow.python.framework.ops.Tensor'>`. Expected a symbolic tensor instance.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-1e856fa1078d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# column t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprobas_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mh_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-12-78d3e2c2efd1>\u001b[0m in \u001b[0;36mrnn_one_step\u001b[1;34m(x_t, h_t)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# convert character id into embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mx_t_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# concatenate x_t embedding and previous h_t state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\hsefs\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    446\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Layer embedding_1 was called with an input that isn't a symbolic tensor. Received type: <class 'tensorflow.python.framework.ops.Tensor'>. Full input: [<tf.Tensor 'Reshape:0' shape=(?, 1) dtype=int32>]. All inputs to the layer should be tensors."
          ]
        }
      ],
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xyGxsTH1F0Em"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "bbSeJ5EnF0En"
      },
      "outputs": [],
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2r6voTQ0F0Es"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "colab_type": "code",
        "id": "9nb1CoweF0Et",
        "outputId": "263d01da-195c-4ee9-ffdf-7bf62a98a17b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0808 07:52:47.782487 140070811703168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0808 07:52:47.880825 140070811703168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n_iCnkv9F0E2"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "colab_type": "code",
        "id": "eMIJr036F0E3",
        "outputId": "2f9fe5a7-7b70-4561-d2f7-87a8bd0f647b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1h6gm2ipF0E6"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "2WrPCloRF0E8"
      },
      "outputs": [],
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "skKanILfF0FA"
      },
      "outputs": [],
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "colab_type": "code",
        "id": "eHSy7zpzF0FE",
        "outputId": "c4231fd9-1634-4a4f-feed-e7fa0d3d54d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Bdililyaaaaaaaa\n",
            " Perhoaoaaaaaaaa\n",
            " Talenitaaaaaaaa\n",
            " Pesnaaaaaaaaaaa\n",
            " Roinaaaaaaaaaaa\n",
            " Marisnaaaaaaaaa\n",
            " Kasselenaaaaaaa\n",
            " Sheaaaaaaaaaaaa\n",
            " Mamalhyaaaaaaaa\n",
            " Finnioaaaaaaaaa\n"
          ]
        }
      ],
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "colab_type": "code",
        "id": "wDrGxBjrF0FJ",
        "outputId": "46ae219f-a573-40c4-b26e-03b1e00ffe82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Trumpoaaaaaaaaa\n",
            " Trumpiahaaaaaaa\n",
            " Trumperaaaaaaaa\n",
            " Trumpolataaaaaa\n",
            " Trumpeltisaaaaa\n",
            " Trumpieaaaaaaaa\n",
            " Trumpaaaaaaaaaa\n",
            " Trumpilaaaaaaaa\n",
            " Trumpllisaaaaaa\n",
            " Trumprrewaaaaaa\n"
          ]
        }
      ],
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G0LErXjgF0FM"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "0zBDzmc-F0FN"
      },
      "outputs": [],
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = \"### YOUR EMAIL HERE ###\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "colab_type": "code",
        "id": "4zQAIDsGF0FW",
        "outputId": "179cbfd2-9da6-41c5-ba3f-ac1ee1e01fa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ]
        }
      ],
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RRZUWmf4F0FZ"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "id": "liKtH21rF0Fa"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "colab_type": "code",
        "id": "v-nNXi0LF0Fb",
        "outputId": "b07a510a-a2a3-4d33-924d-0180c312812a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8b787f236ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3499\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3501\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3012\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         expand_composites=True)\n\u001b[1;32m   2936\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3454\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3455\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    448\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    449\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1752\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1754\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ],
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "\n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:,:,None], time_major=True, dtype='float32')\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0VJ5EQR8F0Fg"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "-HFK3obsF0Fh"
      },
      "outputs": [],
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "W3LtmC9EF0Fm"
      },
      "outputs": [],
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RNN-task.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
