{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "colab_type": "code",
        "id": "op1vO6SbGIbK",
        "outputId": "a03046a6-0a5b-4458-82b9-3923e2c2d814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-08-08 07:47:21--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-08 07:47:21 (44.7 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "\n",
        "setup_google_colab.setup_week5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AkZenhrOF0C7"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "ig6UPODhF0DD",
        "outputId": "e2d88822-d378-4e9b-b297-7c3d6e58780a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "irg4aY_MF0DQ"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "kV_td4mDF0DT"
      },
      "outputs": [],
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "colab_type": "code",
        "id": "uoO-uXVqF0Da",
        "outputId": "952878b5-857c-4d56-bed8-7a719f9902f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ]
        }
      ],
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "colab_type": "code",
        "id": "KC48QNXLF0Dk",
        "outputId": "98bce73f-dff1-4246-bd37-393c72ce9c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGntJREFUeJzt3X+UXWV97/H3h/CjgPwIZgyQBCZiQIGlAaeAVRAvBcKPS9B7i6FeCIoGWrB6ZV0v0NtCRbpSK6WyxNAAaaBCMOVHSQWESFVKa5AJxpBAkAECmTBJBsMPC65o4Hv/2M/oZjhn5vyaOQnP57XWWbPP93n2s7/7THK+Zz97n9mKCMzMLE/btDsBMzNrHxcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAva1JCknvacN2j5bU28T6l0r6dlreR9J/SRrTotyukfQXrcizwthHSnqiVePZyHMRyICkj0j6T0kvS9oo6T8k/X6783o7GcliExHPRcQ7IuL1YXI4S9KDNYx3bkRc1orcBu93RPx7RBzQirFtdGzb7gRsZEnaFfgu8CfAQmB74EhgUzvzsvaQNGa4YmJ58ZHA29/+ABGxICJej4hfRcR9EbF8oIOkz0h6XNKLku6VtG+p7VhJq9JRxDcl/UjSZ1Pbb6cs0vPO9Mlw2/R8N0nXS+qTtFbSVwemNAY+tUr6etruM5JOKI21h6R/lPR8av+XUtvJkpZJeikd4by/lhdC0g5pe89JWp+mRXZMbUdL6pV0gaQNKedPl9Z9p6R/lfSKpIfTvjyY2h5I3X6Wpm0+WVqv4ngVcpucXttfSloMjBvidT1L0tOp7zOSPiXpfcA1wIdSDi+lvvMlzZF0t6RXgY+l2FcHbf9iSS9IWi3pU6X4Dwd+3+XfW7X9Hjy9JOl9aYyXJK2UdEqpbb6kqyXdlfblIUn7Dfd7tNZyEXj7+znwuqQbJJ0gaWy5UdJ04GLgE0AH8O/AgtQ2Drgd+H8Ub0pPAR+uY9vzgc3Ae4BDgOOAz5baDweeSGN/DbheklLbPwE7AQcB7wKuTDkdAswDzgHeCfwDsEjSDjXkM5uiKE5NOU0A/rLUviewW4qfDVxder2uBl5NfWamBwARcVRa/ECatvlODeMNdjOwNL0Wl5XHL5O0M3AVcEJE7AL8AbAsIh4HzgV+nHLYvbTaHwOXA7sAlaaL9kzbnZC2O1fSsFM6Q+z3QK7bAf8K3EfxO/w8cNOgsWcAfwWMBXpSnjaaIsKPt/kDeB/FG3IvxZvyImB8arsHOLvUdxvgNWBf4ExgSalNaYzPpueXAt8utXcCQTHNOJ5iymnHUvvpwA/S8llAT6ltp7TunsBewBvA2Ar7Mge4bFDsCeCjVfY9KN7wRfEmvl+p7UPAM2n5aOBXwLal9g3AEcAY4DfAAaW2rwIPDt5O6XnV8SrkuE/6vexcit088NoOel13Bl4C/kf5tS29pg8Ois0HbqwQ+2opz8HbXgj8RVr+4cDvu9I2qux3b1o+ElgHbFNqXwBcWsrjulLbicCqdv9/ye3hI4EMRMTjEXFWREwEDgb2Bv4+Ne8LfCMdrr8EbKR4w5yQ+q0pjRPl58PYF9gO6CuN/Q8UnwgHrCuN/VpafAcwCdgYES9WGfeCgTHTuJNSrkPpoCg0S0vrfS/FB/wiIjaXnr+W8umgeAMu73str0O18QbbG3gxIl4txZ6tNGDq80mKT/19aSrlvcPkMVyulbY93OtZi72BNRHxxqCxJ5SerystV3t9bAS5CGQmIlZRfAI7OIXWAOdExO6lx44R8Z9AH8UbLABpqmZSabhXKd5YB+xZWl5DcSQwrjTurhFxUA1prgH2kLR7lbbLB+W7U0QsGGbMFyg+mR9UWm+3iKjlTaef4tPyxFJsUpW+jegDxqapngH7VOscEfdGxLEUR0yrgGsHmqqtMsz2K237+bQ81O94OM8DkySV32f2AdbWMYaNMBeBtzlJ700nJyem55MopmWWpC7XABdJOii17ybpj1LbXcBBkj6RTkr+GW9+E1gGHKXiOvbdgIsGGiKij2Iu+ApJu0raRtJ+kj46XM5p3XuAb0kaK2k7SQPzz9cC50o6XIWdJZ0kaZdhxnwjrXulpHelfZ0g6fga8nmd4tzIpZJ2Sp+8zxzUbT3w7uHGqjL+s0A38FeStpf0EeC/V+orabyk6elNexPwXxRTZwM5TJS0fQNpDGz7SOBk4J9TfBnwibTf76E4t1E21H4/RPHp/svpd3h02q9bGsjPRoiLwNvfLylOwD6Urg5ZAqwALgCIiDuAvwFukfRKajshtb0A/BHFCdVfAFOA/xgYOCIWA98BllOc1PzuoG2fSXFJ6mPAi8CtFJ9ea3EGxTz8Koq59C+mbXYDnwO+mcbsoZinrsX/Tf2XpH39PlDrNe3nU5zkXUdx0noBb77M9lLghjTVdFqNY5b9McXvaSNwCXBjlX7bAF+i+JS9EfgoxeW/AP8GrATWSXqhjm2vo3gtnwduAs5NR4xQnJD/NcWb/Q2pvexSqux3RPya4k3/BIojsW8BZ5bGti2Aimles9pI+iHFCcvr2p1LO0n6G2DPiKh4FY/Z1sJHAmY1SNNq709TUIdRTIvc0e68zJrlbwyb1WYXiimgvSmmRq4A7mxrRmYt4OkgM7OMeTrIzCxjW/x00Lhx46Kzs7PdaZiZbTWWLl36QkR0DN9zKygCnZ2ddHd3tzsNM7OthqSK3zivxNNBZmYZcxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGdvivzFsW5bOC++qq//q2SeNUCZm1go+EjAzy9iwRUDSJEk/kPSYpJWSvpDie0haLOnJ9HNsikvSVZJ6JC2XdGhprJmp/5OSfEcmM7M2q+VIYDNwQUQcCBwBnCfpQOBC4P6ImALcn55DcT/RKekxC5gDRdGguHfq4cBhwCUDhcPMzNpj2CIQEX0R8Uha/iXwODABmE5x42nSz1PT8nTgxigsAXaXtBdwPLA4IjZGxIvAYmBaS/fGzMzqUtc5AUmdwCHAQ8D4iOhLTeuA8Wl5ArCmtFpvilWLV9rOLEndkrr7+/vrSdHMzOpQcxGQ9A7gNuCLEfFKuS2Ke1S27D6VETE3Iroioqujo6b7IpiZWQNqKgKStqMoADdFxO0pvD5N85B+bkjxtcCk0uoTU6xa3MzM2qSWq4MEXA88HhF/V2paBAxc4TMTuLMUPzNdJXQE8HKaNroXOE7S2HRC+LgUMzOzNqnly2IfBs4AHpW0LMUuBmYDCyWdDTwLnJba7gZOBHqA14BPA0TERkmXAQ+nfl+JiI0t2QszM2vIsEUgIh4EVKX5mAr9AzivyljzgHn1JGhmZiPH3xg2M8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMN5V5m/FNX8ysHj4SMDPLmIuAmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy1gtt5ecJ2mDpBWl2HckLUuP1QN3HJPUKelXpbZrSut8UNKjknokXZVuW2lmZm1Uy5+NmA98E7hxIBARnxxYlnQF8HKp/1MRMbXCOHOAzwEPUdyCchpwT/0pm5lZqwx7JBARDwAV7wWcPs2fBiwYagxJewG7RsSSdPvJG4FT60/XzMxaqdlzAkcC6yPiyVJssqSfSvqRpCNTbALQW+rTm2IVSZolqVtSd39/f5MpmplZNc0WgdN581FAH7BPRBwCfAm4WdKu9Q4aEXMjoisiujo6OppM0czMqmn4T0lL2hb4BPDBgVhEbAI2peWlkp4C9gfWAhNLq09MMTMza6NmjgT+EFgVEb+d5pHUIWlMWn43MAV4OiL6gFckHZHOI5wJ3NnEts3MrAVquUR0AfBj4ABJvZLOTk0zeOsJ4aOA5emS0VuBcyNi4KTynwLXAT3AU/jKIDOztht2OigiTq8SP6tC7Dbgtir9u4GD68zPzMxGkL8xbGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy5iLgJlZxlwEzMwyVsudxeZJ2iBpRSl2qaS1kpalx4mltosk9Uh6QtLxpfi0FOuRdGHrd8XMzOpVy5HAfGBahfiVETE1Pe4GkHQgxW0nD0rrfEvSmHTf4auBE4ADgdNTXzMza6Nabi/5gKTOGsebDtwSEZuAZyT1AIeltp6IeBpA0i2p72N1Z2xmZi3TzDmB8yUtT9NFY1NsArCm1Kc3xarFK5I0S1K3pO7+/v4mUjQzs6E0WgTmAPsBU4E+4IqWZQRExNyI6IqIro6OjlYObWZmJcNOB1USEesHliVdC3w3PV0LTCp1nZhiDBE3M7M2aehIQNJepacfBwauHFoEzJC0g6TJwBTgJ8DDwBRJkyVtT3HyeFHjaZuZWSsMeyQgaQFwNDBOUi9wCXC0pKlAAKuBcwAiYqWkhRQnfDcD50XE62mc84F7gTHAvIhY2fK9MTOzutRyddDpFcLXD9H/cuDyCvG7gbvrys7MzEZUQ+cEzEZK54V31b3O6tknjUAmZnnwn40wM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjwxYBSfMkbZC0ohT7W0mrJC2XdIek3VO8U9KvJC1Lj2tK63xQ0qOSeiRdJUkjs0tmZlarWo4E5gPTBsUWAwdHxPuBnwMXldqeioip6XFuKT4H+BzFfYenVBjTzMxG2bBFICIeADYOit0XEZvT0yXAxKHGSDem3zUilkREADcCpzaWspmZtUorzgl8Brin9HyypJ9K+pGkI1NsAtBb6tObYhVJmiWpW1J3f39/C1I0M7NKmioCkv4c2AzclEJ9wD4RcQjwJeBmSbvWO25EzI2Irojo6ujoaCZFMzMbQsM3mpd0FnAycEya4iEiNgGb0vJSSU8B+wNrefOU0cQUMzOzNmroSEDSNODLwCkR8Vop3iFpTFp+N8UJ4Kcjog94RdIR6aqgM4E7m87ezMyaMuyRgKQFwNHAOEm9wCUUVwPtACxOV3ouSVcCHQV8RdJvgDeAcyNi4KTyn1JcabQjxTmE8nkEMzNrg2GLQEScXiF8fZW+twG3VWnrBg6uKzszMxtR/sawmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZWcZqKgKS5knaIGlFKbaHpMWSnkw/x6a4JF0lqUfSckmHltaZmfo/KWlm63fHzMzqUeuRwHxg2qDYhcD9ETEFuD89BziB4gbzU4BZwBwoigbF/YkPBw4DLhkoHGZm1h41FYGIeADYOCg8HbghLd8AnFqK3xiFJcDukvYCjgcWR8TGiHgRWMxbC4uZmY2iZs4JjI+IvrS8DhiflicAa0r9elOsWvwtJM2S1C2pu7+/v4kUzcxsKC05MRwRAUQrxkrjzY2Irojo6ujoaNWwZmY2SDNFYH2a5iH93JDia4FJpX4TU6xa3MzM2qSZIrAIGLjCZyZwZyl+ZrpK6Ajg5TRtdC9wnKSx6YTwcSlmZmZtsm0tnSQtAI4GxknqpbjKZzawUNLZwLPAaan73cCJQA/wGvBpgIjYKOky4OHU7ysRMfhks5mZjaKaikBEnF6l6ZgKfQM4r8o484B5NWdnZmYjyt8YNjPLWE1HAtYanRfeVVf/1bNPGqFMzMwKPhIwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGP+noBlx9/XMPsdHwmYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLWcBGQdICkZaXHK5K+KOlSSWtL8RNL61wkqUfSE5KOb80umJlZoxr+nkBEPAFMBZA0huKm8XdQ3E7yyoj4erm/pAOBGcBBwN7A9yXtHxGvN5qDmZk1p1XTQccAT0XEs0P0mQ7cEhGbIuIZinsQH9ai7ZuZWQNaVQRmAAtKz8+XtFzSPEljU2wCsKbUpzfF3kLSLEndkrr7+/tblKKZmQ3WdBGQtD1wCvDPKTQH2I9iqqgPuKLeMSNibkR0RURXR0dHsymamVkVrTgSOAF4JCLWA0TE+oh4PSLeAK7ld1M+a4FJpfUmppiZmbVJK4rA6ZSmgiTtVWr7OLAiLS8CZkjaQdJkYArwkxZs38zMGtTUXxGVtDNwLHBOKfw1SVOBAFYPtEXESkkLgceAzcB5vjLIzKy9mioCEfEq8M5BsTOG6H85cHkz2zQzs9bxN4bNzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZWcZacaP51ZIelbRMUneK7SFpsaQn08+xKS5JV0nqkbRc0qHNbt/MzBrXqiOBj0XE1IjoSs8vBO6PiCnA/ek5FDeln5Ies4A5Ldq+mZk1YKSmg6YDN6TlG4BTS/Ebo7AE2H3QjenNzGwUtaIIBHCfpKWSZqXY+IjoS8vrgPFpeQKwprRub4q9iaRZkroldff397cgRTMzq6SpG80nH4mItZLeBSyWtKrcGBEhKeoZMCLmAnMBurq66lrXzMxq1/SRQESsTT83AHcAhwHrB6Z50s8NqftaYFJp9YkpZmZmbdBUEZC0s6RdBpaB44AVwCJgZuo2E7gzLS8CzkxXCR0BvFyaNjIzs1HW7HTQeOAOSQNj3RwR35P0MLBQ0tnAs8Bpqf/dwIlAD/Aa8Okmt29mZk1oqghExNPAByrEfwEcUyEewHnNbNPMzFrH3xg2M8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLWCv+iqiZlXReeFdd/VfPPmmEMjEbno8EzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZa7gISJok6QeSHpO0UtIXUvxSSWslLUuPE0vrXCSpR9ITko5vxQ6YmVnjmvmewGbggoh4JN1neKmkxantyoj4ermzpAOBGcBBwN7A9yXtHxGvN5FDS/n6bjPLTcNHAhHRFxGPpOVfAo8DE4ZYZTpwS0RsiohnKO4zfFij2zczs+a15JyApE7gEOChFDpf0nJJ8ySNTbEJwJrSar0MXTTMzGyENV0EJL0DuA34YkS8AswB9gOmAn3AFQ2MOUtSt6Tu/v7+ZlM0M7MqmioCkrajKAA3RcTtABGxPiJej4g3gGv53ZTPWmBSafWJKfYWETE3Iroioqujo6OZFM3MbAjNXB0k4Hrg8Yj4u1J8r1K3jwMr0vIiYIakHSRNBqYAP2l0+2Zm1rxmrg76MHAG8KikZSl2MXC6pKlAAKuBcwAiYqWkhcBjFFcWnbclXRlkZpajhotARDwIqELT3UOsczlweaPbNDOz1vI3hs3MMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGmvnGsJm1Qb33vQDf+8Kq85GAmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy9iof1lM0jTgG8AY4LqImD3aOZjZ0Or9Qpq/jLb1GtUiIGkMcDVwLNALPCxpUUQ8NhLba+SblWZmORntI4HDgJ6IeBpA0i3AdIqbz5tZJkb6SMN/WqN2iojR25j0P4FpEfHZ9PwM4PCIOH9Qv1nArPT0AOCJUUuyduOAF9qdRIOce3s499G3teYNzeW+b0R01NJxi/wDchExF5jb7jyGIqk7IrranUcjnHt7OPfRt7XmDaOX+2hfHbQWmFR6PjHFzMysDUa7CDwMTJE0WdL2wAxg0SjnYGZmyahOB0XEZknnA/dSXCI6LyJWjmYOLbRFT1cNw7m3h3MffVtr3jBKuY/qiWEzM9uy+BvDZmYZcxEwM8uYi0CDJI2R9FNJ3213LvWQtLukWyWtkvS4pA+1O6daSPrfklZKWiFpgaTfa3dO1UiaJ2mDpBWl2B6SFkt6Mv0c284cq6mS+9+mfy/LJd0hafd25lhNpdxLbRdICknj2pHbcKrlLunz6bVfKelrI7FtF4HGfQF4vN1JNOAbwPci4r3AB9gK9kHSBODPgK6IOJjiooIZ7c1qSPOBaYNiFwL3R8QU4P70fEs0n7fmvhg4OCLeD/wcuGi0k6rRfN6aO5ImAccBz412QnWYz6DcJX2M4i8qfCAiDgK+PhIbdhFogKSJwEnAde3OpR6SdgOOAq4HiIhfR8RL7c2qZtsCO0raFtgJeL7N+VQVEQ8AGweFpwM3pOUbgFNHNakaVco9Iu6LiM3p6RKK7/dscaq87gBXAl8GttirYKrk/ifA7IjYlPpsGIltuwg05u8p/lG90e5E6jQZ6Af+MU1lXSdp53YnNZyIWEvxKeg5oA94OSLua29WdRsfEX1peR0wvp3JNOEzwD3tTqJWkqYDayPiZ+3OpQH7A0dKekjSjyT9/khsxEWgTpJOBjZExNJ259KAbYFDgTkRcQjwKlvutMRvpfnz6RRFbG9gZ0n/q71ZNS6K67K32E+l1Uj6c2AzcFO7c6mFpJ2Ai4G/bHcuDdoW2AM4Avg/wEJJavVGXATq92HgFEmrgVuA/ybp2+1NqWa9QG9EPJSe30pRFLZ0fwg8ExH9EfEb4HbgD9qcU73WS9oLIP0ckUP7kSLpLOBk4FOx9Xy5aD+KDw4/S/9fJwKPSNqzrVnVrhe4PQo/oZh5aPmJbReBOkXERRExMSI6KU5O/ltEbBWfSiNiHbBG0gEpdAxbx5/xfg44QtJO6ZPQMWwFJ7QHWQTMTMszgTvbmEtd0o2gvgycEhGvtTufWkXEoxHxrojoTP9fe4FD0/+DrcG/AB8DkLQ/sD0j8BdRXQTy83ngJknLganAX7c5n2GlI5dbgUeARyn+3W6xfw5A0gLgx8ABknolnQ3MBo6V9CTFkc0WeUe9Krl/E9gFWCxpmaRr2ppkFVVy3ypUyX0e8O502egtwMyROArzn40wM8uYjwTMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sBLWSNRkF0Do"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "f_JX1TLTF0Dq",
        "outputId": "636cbcdb-8bfd-4fc9-9322-117f629bb625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ]
        }
      ],
      "source": [
        "tokens = list(set(''.join(names))) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5XsdjevnF0Dz"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "seEXIds3F0D1"
      },
      "outputs": [],
      "source": [
        "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "for index, token in enumerate(tokens):\n",
        "    token_to_id[token] = index\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "KylWmvLwF0D7"
      },
      "outputs": [],
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "colab_type": "code",
        "id": "B4Fo44FXF0EG",
        "outputId": "58e090f3-f699-4b43-d609-7bfdb58760ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[41 21  6  0 20  0 45 54  0]\n",
            " [41 42 54 32 47 39  0  0  0]\n",
            " [41 40 47 14 48 48 14 45  0]\n",
            " [41 42 14 32 51  0 31 31 45]]\n"
          ]
        }
      ],
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ItFYyQrF0EK"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "colab_type": "code",
        "id": "BTxvvWX4F0EM",
        "outputId": "253c4706-cdd2-41ef-842c-77c5d1b79c1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 07:48:19.770891 140070811703168 deprecation_wrapper.py:119] From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0808 07:48:19.773764 140070811703168 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0808 07:48:19.775839 140070811703168 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0808 07:48:19.793340 140070811703168 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0808 07:48:19.794673 140070811703168 deprecation_wrapper.py:119] From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "PmNQQTZ4F0EV"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation = 'relu') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = 'softmax') ### YOUR CODE HERE "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ChfnRPzQF0EY"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "l3PzBBX0F0Ea"
      },
      "outputs": [],
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YSZXQDbLF0Eg"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "Ze0gEqzKF0Eh"
      },
      "outputs": [],
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xyGxsTH1F0Em"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "bbSeJ5EnF0En"
      },
      "outputs": [],
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2r6voTQ0F0Es"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "colab_type": "code",
        "id": "9nb1CoweF0Et",
        "outputId": "263d01da-195c-4ee9-ffdf-7bf62a98a17b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0808 07:52:47.782487 140070811703168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0808 07:52:47.880825 140070811703168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n_iCnkv9F0E2"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "colab_type": "code",
        "id": "eMIJr036F0E3",
        "outputId": "2f9fe5a7-7b70-4561-d2f7-87a8bd0f647b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1h6gm2ipF0E6"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "2WrPCloRF0E8"
      },
      "outputs": [],
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "skKanILfF0FA"
      },
      "outputs": [],
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "colab_type": "code",
        "id": "eHSy7zpzF0FE",
        "outputId": "c4231fd9-1634-4a4f-feed-e7fa0d3d54d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Bdililyaaaaaaaa\n",
            " Perhoaoaaaaaaaa\n",
            " Talenitaaaaaaaa\n",
            " Pesnaaaaaaaaaaa\n",
            " Roinaaaaaaaaaaa\n",
            " Marisnaaaaaaaaa\n",
            " Kasselenaaaaaaa\n",
            " Sheaaaaaaaaaaaa\n",
            " Mamalhyaaaaaaaa\n",
            " Finnioaaaaaaaaa\n"
          ]
        }
      ],
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "colab_type": "code",
        "id": "wDrGxBjrF0FJ",
        "outputId": "46ae219f-a573-40c4-b26e-03b1e00ffe82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Trumpoaaaaaaaaa\n",
            " Trumpiahaaaaaaa\n",
            " Trumperaaaaaaaa\n",
            " Trumpolataaaaaa\n",
            " Trumpeltisaaaaa\n",
            " Trumpieaaaaaaaa\n",
            " Trumpaaaaaaaaaa\n",
            " Trumpilaaaaaaaa\n",
            " Trumpllisaaaaaa\n",
            " Trumprrewaaaaaa\n"
          ]
        }
      ],
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G0LErXjgF0FM"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "0zBDzmc-F0FN"
      },
      "outputs": [],
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = \"### YOUR EMAIL HERE ###\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "colab_type": "code",
        "id": "4zQAIDsGF0FW",
        "outputId": "179cbfd2-9da6-41c5-ba3f-ac1ee1e01fa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ]
        }
      ],
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RRZUWmf4F0FZ"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "collapsed": true,
        "id": "liKtH21rF0Fa"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "colab_type": "code",
        "id": "v-nNXi0LF0Fb",
        "outputId": "b07a510a-a2a3-4d33-924d-0180c312812a"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8b787f236ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3499\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3501\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3012\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         expand_composites=True)\n\u001b[1;32m   2936\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3454\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3455\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    448\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    449\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1752\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1754\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ],
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "\n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:,:,None], time_major=True, dtype='float32')\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0VJ5EQR8F0Fg"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "-HFK3obsF0Fh"
      },
      "outputs": [],
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "colab": {},
        "colab_type": "code",
        "id": "W3LtmC9EF0Fm"
      },
      "outputs": [],
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RNN-task.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
